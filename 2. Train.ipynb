{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "2. Train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prhghqjgFVup"
      },
      "source": [
        "## **Images & masks directory list**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "5BKaq-XqFdfZ"
      },
      "source": [
        "# make lists for image and mask directories\n",
        "import glob\n",
        "\n",
        "images_dir = '/outputs/dataset/images'\n",
        "masks_dir = '/outputs/dataset/masks'\n",
        "\n",
        "image_paths = sorted(glob.glob(f'{images_dir}/*'))\n",
        "mask_paths = sorted(glob.glob(f'{masks_dir}/*'))\n",
        "\n",
        "print(f'total images: {len(image_paths)}')\n",
        "print(f'total masks: {len(mask_paths)}')\n",
        "print(image_paths[:5])\n",
        "print(mask_paths[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSBdFPbx51M_"
      },
      "source": [
        "## **Prepare Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLFQlVyX2DiR"
      },
      "source": [
        "import random\n",
        "\n",
        "# number of validation samples\n",
        "val_samples = 50\n",
        "\n",
        "random.Random(1337).shuffle(image_paths)\n",
        "random.Random(1337).shuffle(mask_paths)\n",
        "\n",
        "# Split our img paths into a training and a validation set\n",
        "train_image_paths = image_paths[:-val_samples]\n",
        "train_mask_paths = mask_paths[:-val_samples]\n",
        "\n",
        "val_image_paths = image_paths[-val_samples:]\n",
        "val_mask_paths = mask_paths[-val_samples:]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6QruQbz51NE"
      },
      "source": [
        "from dataset import BuildingDataset\n",
        "\n",
        "img_size = (512, 512)\n",
        "batch_size = 16\n",
        "\n",
        "# Instantiate data Sequences for each split\n",
        "train_gen = BuildingDataset(batch_size,\n",
        "                            img_size,\n",
        "                            train_image_paths,\n",
        "                            train_mask_paths)\n",
        "\n",
        "val_gen = BuildingDataset(batch_size,\n",
        "                          img_size,\n",
        "                          val_image_paths,\n",
        "                          val_mask_paths)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOI32CLa51NF"
      },
      "source": [
        "## **Create and compile the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5Gm5zuv51NG"
      },
      "source": [
        "activation_function = 'sigmoid'\n",
        "num_classes = 1\n",
        "\n",
        "from models import UNet\n",
        "model = UNet(num_classes = num_classes,\n",
        "         image_size = img_size[0], \n",
        "         img_channels = 3,\n",
        "         activation_fn = 'sigmoid')\n",
        "\n",
        "# from models import DeepUNet\n",
        "# model =  DeepUNet(num_classes=num_classes,\n",
        "#              image_size=img_size[0],\n",
        "#              img_channels=3,\n",
        "#              activation_fn = activation_function,\n",
        "#              n_filters_start = 32)\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from loss import bce_dice_loss, dice_coef\n",
        "\n",
        "loss = bce_dice_loss # can use 'binary_crossentropy'\n",
        "optimizer = Adam()\n",
        "\n",
        "# compile model\n",
        "model.compile(optimizer = optimizer, \n",
        "              loss = loss,\n",
        "              metrics = [Precision(), \n",
        "                        Recall(), \n",
        "                        dice_coef])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzTFaP7c51NG"
      },
      "source": [
        "## **Train the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "elTPldOq2Imf"
      },
      "source": [
        "# Train the model, doing validation at the end of each epoch.\n",
        "epochs = 50\n",
        "\n",
        "model.fit(train_gen, \n",
        "          epochs=epochs, \n",
        "          validation_data=val_gen,\n",
        "          verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6J9USi5351NI"
      },
      "source": [
        "## **Save model file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgU20AGe51NI"
      },
      "source": [
        "import os\n",
        "\n",
        "# create folder to save weights\n",
        "weights_save_folder = 'outputs/weights'\n",
        "os.makedirs(weights_save_folder, exist_ok = True)\n",
        "\n",
        "model.save(f'{weights_save_folder}/my_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdyKAC1PKb7w"
      },
      "source": [
        "## **Inference on a single tile**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "qWbFtiPk2Uzc"
      },
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "threshold = 0.95\n",
        "\n",
        "test_img_dir = 'test_image.png'\n",
        "test_mask_dir = 'test_mask.png'\n",
        "\n",
        "# read test image and mask\n",
        "test_image = Image.open(test_img_dir)\n",
        "test_mask = Image.open(test_mask_dir)\n",
        "\n",
        "# make predictions\n",
        "pred_img = np.expand_dims(test_image, axis = 0)\n",
        "test_preds = model.predict(pred_img)\n",
        "test_preds = np.squeeze(test_preds)\n",
        "test_preds = test_preds > threshold\n",
        "\n",
        "# plot the results\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
        "\n",
        "ax1.imshow(test_image)\n",
        "ax1.title.set_text('Image')\n",
        "\n",
        "ax2.imshow(test_preds)\n",
        "ax2.title.set_text('Predictions')\n",
        "\n",
        "ax3.imshow(test_mask)\n",
        "ax3.title.set_text('Ground Truth')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}